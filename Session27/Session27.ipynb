{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, students will be using the K-nearest neighbors algorithm to predict how many points NBA players scored in the 2013-2014 season.\n",
    "\n",
    "A look at the data:\n",
    "\n",
    "Before we dive into the algorithm, let’s take a look at our data. Each row in the data contains information on how a player performed in the 2013-2014 NBA season.\n",
    "\n",
    "Download 'nba_2013.csv' file from this link:\n",
    "https://www.dropbox.com/s/b3nv38jjo5dxcl6/nba_2013.csv?dl=0\n",
    "\n",
    "Here are some selected columns from the data:<br />\n",
    "player - name of the player<br />\n",
    "pos - the position of the player<br />\n",
    "g - number of games the player was in<br />\n",
    "gs - number of games the player started<br />\n",
    "pts - total points the player scored<br />\n",
    "\n",
    "There are many more columns in the data, mostly containing information about average player game performance over the course of the season.\n",
    "\n",
    "See this site for an explanation of the rest of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read dataset and identify which columns are present in dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['player', 'pos', 'age', 'bref_team_id', 'g', 'gs', 'mp', 'fg',\n",
       "       'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.',\n",
       "       'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk',\n",
       "       'tov', 'pf', 'pts', 'season', 'season_end'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "with open(\"./nba_2013.csv\", \"r\") as csvfile:\n",
    "    nba = pandas.read_csv(csvfile)\n",
    "\n",
    "nba.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean distance\n",
    "\n",
    "Before we can predict using KNN, we need to find some way to figure out which data rows are “closest” to the row we’re trying to predict on.\n",
    "\n",
    "We can use the principle of euclidean distance to find the most similar NBA players to Lebron James."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Lebron James from our dataset\n",
    "selected_player = nba[nba[\"player\"] == \"LeBron James\"].iloc[0]\n",
    "\n",
    "# Choose only the numeric columns (we'll use these to compute euclidean distance)\n",
    "distance_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts']\n",
    "\n",
    "def euclidean_distance(row):\n",
    "    inner_value = 0\n",
    "    for k in distance_columns:\n",
    "        inner_value += (row[k] - selected_player[k]) ** 2\n",
    "    return math.sqrt(inner_value)\n",
    "\n",
    "# Find the distance from each player in the dataset to lebron.\n",
    "lebron_distance = nba.apply(euclidean_distance, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing columns\n",
    "\n",
    "You may have noticed that horsepower in the cars example had a much larger impact on the final distance than racing_stripes did. This is because horsepower values are much larger in absolute terms, and thus dwarf the impact of racing_stripes values in the euclidean distance calculations.\n",
    "\n",
    "This can be bad, because a variable having larger values doesn’t necessarily make it better at predicting what rows are similar.\n",
    "\n",
    "A simple way to deal with this is to normalize all the columns to have a mean of 0, and a standard deviation of 1. This will ensure that no single column has a dominant impact on the euclidean distance calculations.\n",
    "\n",
    "To set the mean to 0, we have to find the mean of a column, then subtract the mean from every value in the column. To set the standard deviation to 1, we divide every value in the column by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numeric columns from the NBA dataset\n",
    "nba_numeric = nba[distance_columns]\n",
    "\n",
    "# Normalize all of the numeric columns\n",
    "nba_normalized = (nba_numeric - nba_numeric.mean()) / nba_numeric.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the nearest neighbor\n",
    "\n",
    "We now know enough to find the nearest neighbor of a given row in the NBA dataset. We can use the distance.euclidean function from scipy.spatial, a much faster way to calculate euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# Fill in NA values in nba_normalized\n",
    "nba_normalized.fillna(0, inplace=True)\n",
    "\n",
    "# Find the normalized vector for lebron james.\n",
    "lebron_normalized = nba_normalized[nba[\"player\"] == \"LeBron James\"]\n",
    "\n",
    "# Find the distance between lebron james and everyone else.\n",
    "euclidean_distances = nba_normalized.apply(lambda row: distance.euclidean(row, lebron_normalized), axis=1)\n",
    "\n",
    "# Create a new dataframe with distances.\n",
    "distance_frame = pandas.DataFrame(data={\"dist\": euclidean_distances, \"idx\": euclidean_distances.index})\n",
    "distance_frame.sort_values(\"dist\", inplace=True)\n",
    "\n",
    "# Find the most similar player to lebron (the lowest distance to lebron is lebron, the second smallest is the most similar non-lebron player)\n",
    "second_smallest = distance_frame.iloc[1][\"idx\"]\n",
    "most_similar_to_lebron = nba.loc[int(second_smallest)][\"player\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating training and testing sets\n",
    "\n",
    "Now that we know how to find the nearest neighbors, we can make predictions on a test set. We’ll try to predict how many points a player scored using the 5 closest neighbors. We’ll find neighbors by using all the numeric columns in the dataset to generate similarity scores.\n",
    "\n",
    "First, we have to generate test and train sets. In order to do this, we’ll use random sampling. We’ll randomly shuffle the index of the nba dataframe, and then pick rows using the randomly shuffled values.\n",
    "\n",
    "If we didn’t do this, we’d end up predicting and training on the same data set, which would overfit. We could do cross validation also, which would be slightly better, but slightly more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy.random import permutation\n",
    "\n",
    "# Randomly shuffle the index of nba.\n",
    "random_indices = permutation(nba_normalized.index)\n",
    "\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = math.floor(len(nba_normalized)/3)\n",
    "\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "test = nba_normalized.loc[random_indices[1:test_cutoff]]\n",
    "\n",
    "# Generate the train set with the rest of the data.\n",
    "train = nba_normalized.loc[random_indices[test_cutoff:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn for k nearest neighbors\n",
    "\n",
    "Sklearn performs the normalization and distance finding automatically, and lets us specify how many neighbors we want to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0964998 ],\n",
       "       [-0.91913625],\n",
       "       [-1.00374109],\n",
       "       [-0.50631562],\n",
       "       [-0.34390832],\n",
       "       [ 1.78354216],\n",
       "       [ 1.87154821],\n",
       "       [-1.01139379],\n",
       "       [-0.73292055],\n",
       "       [-0.09604589],\n",
       "       [ 0.51914613],\n",
       "       [-0.89362725],\n",
       "       [ 0.98681111],\n",
       "       [ 0.92941586],\n",
       "       [-0.31754903],\n",
       "       [-1.00586684],\n",
       "       [ 0.42561314],\n",
       "       [-1.09599864],\n",
       "       [-0.81965115],\n",
       "       [-0.82900445],\n",
       "       [-0.66277081],\n",
       "       [-0.72314211],\n",
       "       [-0.98843569],\n",
       "       [ 0.229619  ],\n",
       "       [-0.11050099],\n",
       "       [-0.26440528],\n",
       "       [ 1.74017687],\n",
       "       [ 1.87792546],\n",
       "       [-1.02754949],\n",
       "       [ 0.88902661],\n",
       "       [-0.77713615],\n",
       "       [-0.97227999],\n",
       "       [ 1.19045795],\n",
       "       [-0.21636333],\n",
       "       [-0.50461502],\n",
       "       [ 1.82903321],\n",
       "       [-0.10752494],\n",
       "       [ 0.11695425],\n",
       "       [-0.93444164],\n",
       "       [-0.69678281],\n",
       "       [-0.38727362],\n",
       "       [ 0.46047543],\n",
       "       [-0.07266264],\n",
       "       [ 1.74570382],\n",
       "       [-1.01564529],\n",
       "       [-0.8515374 ],\n",
       "       [ 0.53530183],\n",
       "       [ 2.0484106 ],\n",
       "       [-0.77713615],\n",
       "       [-1.02202254],\n",
       "       [ 0.10930155],\n",
       "       [-0.24654898],\n",
       "       [-0.89872905],\n",
       "       [-0.36176462],\n",
       "       [ 0.18412795],\n",
       "       [-0.18405193],\n",
       "       [-0.97568119],\n",
       "       [-1.01096864],\n",
       "       [-0.32690233],\n",
       "       [ 0.52892458],\n",
       "       [-0.93869314],\n",
       "       [-0.95867519],\n",
       "       [-0.42128562],\n",
       "       [-0.87662125],\n",
       "       [-1.00076504],\n",
       "       [-1.01522014],\n",
       "       [ 0.58461923],\n",
       "       [-0.59389651],\n",
       "       [ 0.21133755],\n",
       "       [ 0.67687677],\n",
       "       [-0.65554326],\n",
       "       [-0.9000045 ],\n",
       "       [-0.44126767],\n",
       "       [-0.47187847],\n",
       "       [-0.8761961 ],\n",
       "       [-0.16449503],\n",
       "       [ 1.0854459 ],\n",
       "       [-1.04838184],\n",
       "       [ 1.21214059],\n",
       "       [-0.43276467],\n",
       "       [-0.56158511],\n",
       "       [ 1.44469763],\n",
       "       [-0.29841728],\n",
       "       [-0.96760334],\n",
       "       [-0.68998041],\n",
       "       [ 0.37587059],\n",
       "       [-0.99353749],\n",
       "       [-1.00799259],\n",
       "       [ 1.15474535],\n",
       "       [-0.8906512 ],\n",
       "       [-0.44041737],\n",
       "       [ 2.53818338],\n",
       "       [-0.79414215],\n",
       "       [ 0.20283455],\n",
       "       [ 0.48555928],\n",
       "       [ 0.60927793],\n",
       "       [ 0.60120008],\n",
       "       [-0.27630948],\n",
       "       [ 0.61990667],\n",
       "       [-0.88682485],\n",
       "       [ 1.62623667],\n",
       "       [ 1.36009279],\n",
       "       [-1.09599864],\n",
       "       [ 0.31507414],\n",
       "       [-0.32052508],\n",
       "       [ 0.30061904],\n",
       "       [ 0.45239758],\n",
       "       [-0.96165124],\n",
       "       [ 0.70578697],\n",
       "       [-0.39747722],\n",
       "       [-0.26142923],\n",
       "       [-0.8608907 ],\n",
       "       [-0.73121995],\n",
       "       [-0.9076572 ],\n",
       "       [ 3.11383645],\n",
       "       [-1.00204049],\n",
       "       [-0.64363906],\n",
       "       [-0.61302826],\n",
       "       [-0.98375904],\n",
       "       [-0.57816596],\n",
       "       [ 1.1024519 ],\n",
       "       [-0.95527399],\n",
       "       [-0.66234566],\n",
       "       [-0.88087275],\n",
       "       [ 1.20703879],\n",
       "       [ 1.70191337],\n",
       "       [ 0.61565518],\n",
       "       [-0.18490223],\n",
       "       [ 0.03490031],\n",
       "       [ 1.49911683],\n",
       "       [-0.95527399],\n",
       "       [ 0.94472126],\n",
       "       [-1.07346569],\n",
       "       [-0.09136924],\n",
       "       [-0.96165124],\n",
       "       [-0.46380062],\n",
       "       [-0.96547759],\n",
       "       [-0.93699254],\n",
       "       [ 0.94854761],\n",
       "       [-0.28353703],\n",
       "       [ 0.15691835],\n",
       "       [-0.98375904],\n",
       "       [ 1.54418273],\n",
       "       [-0.49823777],\n",
       "       [ 1.80267391],\n",
       "       [ 0.42858918],\n",
       "       [-0.40768082],\n",
       "       [ 0.28999029],\n",
       "       [ 1.37752394],\n",
       "       [-0.8557889 ],\n",
       "       [ 0.10334945],\n",
       "       [ 1.43194313],\n",
       "       [-0.7316451 ],\n",
       "       [-0.97440574],\n",
       "       [-0.8090224 ],\n",
       "       [ 1.1390148 ],\n",
       "       [ 1.0446315 ],\n",
       "       [-0.55563301],\n",
       "       [ 0.1981579 ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The columns that we will be making predictions with.\n",
    "x_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf']\n",
    "\n",
    "# The column that we want to predict.\n",
    "y_column = [\"pts\"]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create the knn model.\n",
    "# Look at the five closest neighbors.\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Fit the model on the training data.\n",
    "knn.fit(train[x_columns], train[y_column])\n",
    "\n",
    "# Make point predictions on the test set using the fit model.\n",
    "predictions = knn.predict(test[x_columns])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing error\n",
    "\n",
    "Now that we know our point predictions, we can compute the error involved with our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pts    0.0292\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the actual values for the test set.\n",
    "actual = test[y_column]\n",
    "\n",
    "# Compute the mean squared error of our predictions.\n",
    "mse = (((predictions - actual) ** 2).sum()) / len(predictions)\n",
    "mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
